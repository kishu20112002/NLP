{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01203b9e-2b0a-46db-8077-857baf4af68f",
   "metadata": {},
   "source": [
    "# => Bag of words, TF And IDF\n",
    "\n",
    "## 1 NLP - Components in NLP Bag - of - Words\n",
    "- It is a method of extracting essential features from eaw text\n",
    "- So that we can use it for machine learning models\n",
    "- A bag of words model converts the raw text into words and it also counts the frequency for the words in the text\n",
    "\n",
    "# - Raw text => clean Text => Tokenize => Build Vocob => Generate Vectore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63ff85d-c72a-42f0-9ec6-9d4da3bb2441",
   "metadata": {},
   "source": [
    "### 1.1 Raw Text \n",
    "- This is the original text on which we want to perform analysis  (direct taken for client)\n",
    "\n",
    "### 1.2 Clean Text\n",
    "- Since our raw text contains some unnecessary data like punctuation marks and stopwords, so we need to clean up our text\n",
    "\n",
    "\n",
    "### 1.3 Tokenize \n",
    "- Tokenization represents the sentence as a group of tokens or words\n",
    "\n",
    "### 1.4 Building Vocab\n",
    "- It contains total words used in the text after removing unnecessary data\n",
    "\n",
    "\n",
    "### 1.5 Generate Vocab\n",
    "- It contains the words along with their frequencies in the sentences\n",
    "\n",
    "\n",
    "## 2 Use case\n",
    "### Let's few sentence\n",
    "- jim and pan travelled by bus\n",
    "- The train was late\n",
    "- The flight was full travelling by flight is expensive\n",
    "\n",
    "### 2.1 Creating a basic Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1ef3c41-5fa4-4964-8cac-97bce6b4e89a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Sentence1 Sentence2   Sentence3\n",
      "0        Jim       The         The\n",
      "1        and     train      flight\n",
      "2        Pam       was         was\n",
      "3  travelled      late        full\n",
      "4         by       NaN  Travelling\n",
      "5        the       NaN          by\n",
      "6        bus       NaN      flight\n",
      "7        NaN       NaN          is\n",
      "8        NaN       NaN   expensive\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv(\"/Users/apple/Downloads/sentences.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662d289e-e25d-43f2-a70d-d6230120fe4e",
   "metadata": {},
   "source": [
    "### 2.2 Words with frequences\n",
    "\n",
    "### 2.3 Combining all the words\n",
    "\n",
    "### 2.4 Final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84131b19-f412-4c94-954b-8cda6d87e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 0 0 0 0 0 1 0 1 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1]\n",
      " [0 0 1 1 1 1 1 1 0 0 0 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Bag of the words\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "Sentences=[\"Jim and pam travelled by bus\",\n",
    "          \"the train was late\",\n",
    "          \"Thr fight was full. travelling by flight is expensive\"]\n",
    "\n",
    "cv=CountVectorizer()\n",
    "\n",
    "B_O_W=cv.fit_transform(Sentences).toarray()\n",
    "\n",
    "print(B_O_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549642ae-3857-4dc6-90c1-8f679d8a9bb6",
   "metadata": {},
   "source": [
    "# Application\n",
    "- This concept we can use in nlp application\n",
    "- Infomation retrieval from documents\n",
    "- Classification of documents\n",
    "\n",
    "# Limitation\n",
    "- Semantic meaning:\n",
    "  - It does not consider the semantic meaning of a word\n",
    "- Vector size:\n",
    "  - For large documents the vector size increase , which may result in higher computation time.?\n",
    "- Preprocessing\n",
    "  - In preprocessing we, need to perform data cleansing before using it\n",
    " \n",
    "\n",
    "## 3 Term Frequency-Inverse Document Frequency (TF-IDF)  # very imp interview question\n",
    "- \"Term Frequency-Inverse Document Frequency , is a numerical statistic that is intended to reflect how important a word is to a document in a collection \"\n",
    "\n",
    "- Here's a smaple of reviews about a particular horror movie:\n",
    "- Review 1: This movie is very scary and long\n",
    "- Review 2: This movie is not scary and is slow\n",
    "- Review 3: This movie is spooky and good\n",
    "\n",
    "# TF : Term Frequency = Frequency of the word in the sentence / Total number of words in the sentence\n",
    "\n",
    "| Term   | Review 1 | Review 2 | Review 3 | TF (Review 1) | TF (Review 2) | TF (Review 3) |\n",
    "| ------ | -------- | -------- | -------- | ------------- | ------------- | ------------- |\n",
    "| This   | 1        | 1        | 1        | 1/7           | 1/8           | 1/6           |\n",
    "| movie  | 1        | 1        | 1        | 1/7           | 1/8           | 1/6           |\n",
    "| is     | 1        | 2        | 1        | 1/7           | 1/4           | 1/6           |\n",
    "| very   | 1        | 0        | 0        | 1/7           | 0             | 0             |\n",
    "| scary  | 1        | 1        | 0        | 1/7           | 1/8           | 0             |\n",
    "| and    | 1        | 1        | 1        | 1/7           | 1/8           | 1/6           |\n",
    "| long   | 1        | 0        | 0        | 1/7           | 0             | 0             |\n",
    "| not    | 0        | 1        | 0        | 0             | 1/8           | 0             |\n",
    "| slow   | 0        | 1        | 0        | 0             | 1/8           | 0             |\n",
    "| spooky | 0        | 0        | 1        | 0             | 0             | 1/6           |\n",
    "| good   | 0        | 0        | 1        | 0             | 0             | 1/6           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8da8b3a-8a4f-4f26-9400-16e68f6fb0a4",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency (IDF)\n",
    "- IDF is a measure of how important a term is in a sentence\n",
    "- We need the IDF value because computing just the TF alone is not sufficient to understand the importance of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9469ff9e-1402-4662-941e-ded282b197f1",
   "metadata": {},
   "source": [
    "idft=log/number of documents / number of documents with term 't'\n",
    "\n",
    "## - Example : Review 2\n",
    "- IDF ('movie') = log (3/3)=0 \n",
    "- IDF ('is ') = log (3/3) =0\n",
    "-  IDF ('not ') = log (3/1) =0.48\n",
    "-  IDF ('scaty ') = log (3/2) =0.18\n",
    "-  IDF ('and ') = log (3/3) =0\n",
    "-  IDF ('slow ') = log (3/1) =0.48\n",
    "\n",
    "\n",
    "- We can now compute the TF-IDF score for each word in the corpus\n",
    "- Words with a higher score are more important and lower score are less important\n",
    "\n",
    "\n",
    "## Calculation final TF-IDF values\n",
    "\n",
    "- TF - IDF = TF * IDF\n",
    "\n",
    "### Example\n",
    "\n",
    "TF-IDF('This')= TF('this') * IDF('this') = 1/8 * 0 = 0 \n",
    "\n",
    "\n",
    "| Term   | TF-IDF (Review 1) | TF-IDF (Review 2) | TF-IDF (Review 3) |\n",
    "| ------ | ----------------- | ----------------- | ----------------- |\n",
    "| This   | 0.000             | 0.000             | 0.000             |\n",
    "| movie  | 0.000             | 0.000             | 0.000             |\n",
    "| is     | 0.000             | 0.000             | 0.000             |\n",
    "| very   | 0.068             | 0.000             | 0.000             |\n",
    "| scary  | 0.025             | 0.022             | 0.000             |\n",
    "| and    | 0.000             | 0.000             | 0.000             |\n",
    "| long   | 0.068             | 0.000             | 0.000             |\n",
    "| not    | 0.000             | 0.060             | 0.000             |\n",
    "| slow   | 0.000             | 0.060             | 0.000             |\n",
    "| spooky | 0.000             | 0.000             | 0.080             |\n",
    "| good   | 0.000             | 0.000             | 0.080             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d0eb76-c73f-4584-a995-b47df58d0995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow M1)",
   "language": "python",
   "name": "tf_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
