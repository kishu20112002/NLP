{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72c6a638-85c1-4ecb-97ab-3038b0166312",
   "metadata": {},
   "source": [
    "# NLP\n",
    "\n",
    "## Numerical => ML\n",
    "## unstructured => DL\n",
    "## Text data => NLP (Natural Language Processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9f57a-f8f8-47fa-a164-f1c09c7e1507",
   "metadata": {},
   "source": [
    "# => Data Analysis   => Pandas\n",
    "# => Data viz        => matplotlib, seaborn\n",
    "# => array creation   => numpy \n",
    "# => Text analytics nlp   => nltk (basic lib) spacy (adv lib) huggingface (adv lib )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7bf3a0-b307-4741-be39-7aa62d7da9b3",
   "metadata": {},
   "source": [
    "# 1 NLP - Introduction\n",
    "\n",
    "## 1 Natural Language \n",
    "-  We are all used communicate with natural language\n",
    "  - We may speak to each other on daily base for different purpose\n",
    "  - It is very easy to speak than to write\n",
    "  - We are surrounded by text\n",
    "\n",
    "-  Think about how much text you see each day\n",
    "  - Signs/signals\n",
    "  - Menus\n",
    "  - Email\n",
    "  - SMS\n",
    "  - Web Pages and much more.....\n",
    "  - The list is endless.\n",
    "\n",
    "## 2 Now think about speech \n",
    "- We may speak to each other on daily base for different purpose\n",
    "- It is very easy to speak than to write\n",
    "\n",
    "## 3 Text data\n",
    "- We need understand more about text related data\n",
    "- Text data also having separate methodologies to analyse the data\n",
    "\n",
    "## 4 Natural Language Processing\n",
    "- The short name for Natural Language Processing is NLP\n",
    "- NPL is a way of computers to analyse , Understand and derive meaning from human language such as English , Spanish , Hindi , etc\n",
    "- With NLP machine learning algorithm can be applied to speech and text\n",
    "\n",
    "## 5 NLP popularity is raising everyday\n",
    "- Yes, the popularity of NLP is a rising every day\n",
    "- With NLP a computer can understand the human language while speaking\n",
    "- By using big data we can make communication in between human and machine\n",
    "- With NLP an intelligent system such as a robot can perform according to our instruction issued in a plan language such as English\n",
    "\n",
    "## 6 IMP components in NLP\n",
    "- There are mainly two components in NLP\n",
    "  - Syntax\n",
    "  - Semantic analysis\n",
    "\n",
    "### Syntax\n",
    "- Syntax explains about arrangement of the words in sentence and grammar as well\n",
    "- NLP makes use of syntax to analyse to get the meaning from a language depending or grammatical rules\n",
    "- Some syntax techniques that are used for this include\n",
    "  - Parasing  (reading)\n",
    "  - Word segmentation   (openai tokenizer)\n",
    "  - Sentence breaking   (Sentence tokenizer)\n",
    "  - Morphological segmentation and stemming\n",
    "\n",
    "## 7 Semantics \n",
    "- Semantic is associate with the use and the meaning of various words\n",
    "- In NLP algorithm are used to analyse and determine the meaning and structure of sentences\n",
    "- Some NLP techniques used for semantics include word understanding named entity recognition and natural language genertaion\n",
    "\n",
    "## 8 Deep learning importance\n",
    "- Most of the current approaches to NLP are using deep learning\n",
    "- Deep learning is a type of artificial intelligence that relies on the patterns in data to improve the understanding of a program\n",
    "- Deep learning models usually require huge amounts of labelled data to train and identify any correleation between the data elements\n",
    "\n",
    "## 9 NLTk\n",
    "- NLTK means Natural Language Toolkit\n",
    "- It is a python module to work with NLP\n",
    "- It is open source library\n",
    "- To install this library\n",
    "  - pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38577e97-186d-44da-9d2f-592a89bdd541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: click in /opt/miniconda3/lib/python3.13/site-packages (from nltk) (8.2.1)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/lib/python3.13/site-packages (from nltk) (1.5.3)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /opt/miniconda3/lib/python3.13/site-packages (from nltk) (4.67.1)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "Downloading regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl (288 kB)\n",
      "Installing collected packages: regex, nltk\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [nltk][32m1/2\u001b[0m [nltk]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nltk-3.9.2 regex-2025.11.3\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc262b17-c500-4849-81b2-49e447ffdd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                  Version\n",
      "------------------------ -----------\n",
      "anaconda-anon-usage      0.7.5\n",
      "anaconda-auth            0.12.3\n",
      "anaconda-cli-base        0.7.0\n",
      "annotated-types          0.6.0\n",
      "archspec                 0.2.5\n",
      "boltons                  25.0.0\n",
      "brotlicffi               1.2.0.0\n",
      "certifi                  2025.11.12\n",
      "cffi                     2.0.0\n",
      "charset-normalizer       3.4.4\n",
      "click                    8.2.1\n",
      "conda                    25.11.1\n",
      "conda-anaconda-telemetry 0.3.0\n",
      "conda-anaconda-tos       0.2.2\n",
      "conda-content-trust      0.2.0\n",
      "conda-libmamba-solver    25.11.0\n",
      "conda-package-handling   2.4.0\n",
      "conda_package_streaming  0.12.0\n",
      "cryptography             46.0.3\n",
      "distro                   1.9.0\n",
      "frozendict               2.4.6\n",
      "idna                     3.11\n",
      "jaraco.classes           3.4.0\n",
      "jaraco.context           0.0.0\n",
      "jaraco.functools         4.1.0\n",
      "joblib                   1.5.3\n",
      "jsonpatch                1.33\n",
      "jsonpointer              3.0.0\n",
      "keyring                  25.7.0\n",
      "libmambapy               2.3.2\n",
      "markdown-it-py           4.0.0\n",
      "mdurl                    0.1.2\n",
      "menuinst                 2.4.2\n",
      "more-itertools           10.8.0\n",
      "msgpack                  1.1.1\n",
      "nltk                     3.9.2\n",
      "numpy                    2.4.0\n",
      "packaging                25.0\n",
      "pandas                   2.3.3\n",
      "pip                      25.3\n",
      "pkce                     1.0.3\n",
      "platformdirs             4.5.0\n",
      "pluggy                   1.5.0\n",
      "pycosat                  0.6.6\n",
      "pycparser                2.23\n",
      "pydantic                 2.12.4\n",
      "pydantic_core            2.41.5\n",
      "pydantic-settings        2.12.0\n",
      "Pygments                 2.19.2\n",
      "PyJWT                    2.10.1\n",
      "PySocks                  1.7.1\n",
      "python-dateutil          2.9.0.post0\n",
      "python-dotenv            1.1.0\n",
      "pytz                     2025.2\n",
      "readchar                 4.2.1\n",
      "regex                    2025.11.3\n",
      "requests                 2.32.5\n",
      "rich                     14.2.0\n",
      "ruamel.yaml              0.18.16\n",
      "ruamel.yaml.clib         0.2.14\n",
      "scikit-learn             1.8.0\n",
      "scipy                    1.16.3\n",
      "semver                   3.0.4\n",
      "setuptools               80.9.0\n",
      "shellingham              1.5.4\n",
      "six                      1.17.0\n",
      "threadpoolctl            3.6.0\n",
      "tomli                    2.2.1\n",
      "tqdm                     4.67.1\n",
      "truststore               0.10.1\n",
      "typer                    0.20.0\n",
      "typer-slim               0.20.0\n",
      "typing_extensions        4.15.0\n",
      "typing-inspection        0.4.2\n",
      "tzdata                   2025.3\n",
      "urllib3                  2.6.1\n",
      "wheel                    0.45.1\n",
      "zstandard                0.24.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3863509-f6bc-4861-aaed-23d9bb000966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow M1)",
   "language": "python",
   "name": "tf_m1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
